
Reactive microservices
  Traditionally, as Java developers, we are used to implementing synchronous communication using blocking 
  I/O, for example, a RESTful JSON API over HTTP. Using a blocking I/O means that a thread is allocated 
  from the operating system for the length of the request. If the number of concurrent requests goes up, a 
  server might run out of available threads in the operating system, causing problems ranging from longer 
  response times to crashing servers. Using a microservice architecture typically makes this problem even worse, 
  where typically a chain of cooperating microservices is used to serve a request. The more microservices involved 
  in serving a request, the faster the available threads will be drained.
Solution
  Use non-blocking I/O to ensure that no threads are allocated while waiting for processing 
  to occur in another service, that is, a database or another microservice.

A fat JAR file contains not only the classes and resource files of the application itself but also all the JAR 
  files the application depends on. This means that the fat JAR file is the only JAR file required to run the 
  application; that is, we only need to transfer one JAR file to an environment where we want to run the application 
  instead of transferring the application’s JAR file along with all the JAR files the application depends on.

Spring Data
Entity
  An entity describes the data that will be stored by Spring Data. Entity classes are, in general, annotated 
  with a mix of generic Spring Data annotations and annotations that are specific to each database technology.
  (like: @Table(name = "review") for sql dbs,  and @Document for nosql dbs)
  
Repositories
  Repositories are used to store and access data from different types of databases. In its most basic form, 
  a repository can be declared as a Java interface, and Spring Data will generate its implementation on the 
  fly using opinionated conventions. These conventions can be overridden and/or complemented by additional 
  configuration and, if required, some Java code.
  Spring Data also comes with some base Java interfaces, for example, CrudRepository, to make the definition 
  of a repository even simpler. The base interface, CrudRepository, provides us with standard methods for 
  create, read, update, and delete operations.

The core concepts in Spring Cloud Stream are as follows:
-- Message: A data structure that’s used to describe data sent to and received from a messaging system.
-- Publisher: Sends messages to the messaging system, also known as a Supplier.
-- Subscriber: Receives messages from the messaging system, also known as a Consumer.
-- Destination: Used to communicate with the messaging system. Publishers use output destinations and 
   subscribers use input destinations. Destinations are mapped by the specific binders to queues and topics 
   in the underlying messaging system.
-- Binder: A binder provides the actual integration with a specific messaging system, similar to
   what a JDBC driver does for a specific type of database.


plugins {
  id 'java'
  id 'org.springframework.boot' version '3.0.4'
  id 'io.spring.dependency-management' version '1.1.0'
}

-- The java plugin adds the Java compiler to the project.
-- The plugins org.springframework.boot and io.spring.dependency-management are declared,
   which together ensure that Gradle will build a fat JAR file and that we don’t need to specify any
   explicit version numbers on our Spring Boot starter dependencies. Instead, they are implied
   by the version of the org.springframework.boot plugin, that is, 3.0.4.

# in ./03-dockerize/ application.yml files:  Spring profiles can be used to specify the environment-specific 
  configuration, which, in this case, is a configuration that is only to be used when running the microservice 
  in a Docker container. Other examples are configurations that are specific to dev, test, and production 
  environments. Values in a profile override values from the default profile. By using YAML files, 
  multiple Spring profiles can be placed in the same file, separated by ---.

# When it comes to handling the suboptimal packaging of fat JAR files in Docker images, Spring Boot
  addressed this issue in v2.3.0, making it possible to extract the content of a fat JAR file into a number
  of folders. By default, Spring Boot creates the following folders after extracting a fat JAR file:
• dependencies, containing all dependencies as JAR files
• spring-boot-loader, containing Spring Boot classes that know how to start a Spring Boot application
• snapshot-dependencies, containing snapshot dependencies, if any
• application, containing application class files and resources

Writing automated tests that focus on persistence: 
  When writing persistence tests, we want to start a database when the tests begin and tear it down
  when the tests are complete. However, we don’t want the tests to wait for other resources to start up,
  for example, a web server such as Netty (which is required at runtime).
  Spring Boot comes with two class-level annotations tailored to this specific requirement:
- @DataMongoTest: This annotation starts up a MongoDB database when the test starts.
- @DataJpaTest: This annotation starts up a SQL database when the test starts:
   • By default, Spring Boot configures the tests to roll back updates to the SQL database to 
     minimize the risk of negative side effects on other tests. In our case, this behavior will cause 
     some of the tests to fail. Therefore, automatic rollback is disabled with the class-level 
     annotation @Transactional(propagation = NOT_SUPPORTED).

-- The reactive support in Spring 5 is based on Project Reactor (https://projectreactor.io). Project Reactor 
   is based on the Reactive Streams specification (http://www.reactive-streams.org), a standard for building
   reactive applications. Project Reactor is fundamental – it is what Spring WebFlux, Spring WebClient, and 
   Spring Data rely on to provide their reactive and non-blocking features.
   The programming model is based on processing streams of data, and the core data types in Project
   Reactor are Flux and Mono. A Flux object is used to process a stream of 0...n elements and a Mono
   object is used to process a stream that either is empty or returns at most one element
   
## Spring Cloud Stream
-- The programming model is based on a functional paradigm, where functions implementing one of
   the functional interfaces Supplier, Function, or Consumer in the java.util.function package can
   be chained together to perform decoupled event-based processing. To trigger such functional-based
   processing externally, from non-functional code, the helper class StreamBridge can be used

# Handling challenges with messaging
- Consumer groups
  The problem here is, if we scale up the number of instances of a message consumer, for example, if
  we start two instances of the product microservice, both instances of the product microservice will
  consume the same messages,
- Retries and dead-letter queues If a consumer fails to process a message, it may be re-queued for the 
  failing consumer until it is successfully processed. If the content of the message is invalid, also 
  known as a poisoned message, the message will block the consumer from processing other messages until 
  it is manually removed. If the failure is due to a temporary problem, for example, the database can’t be 
  reached due to a temporary network error, the processing will probably succeed after a number of retries.
  It must be possible to specify the number of retries until a message is moved to another storage for fault 
  analysis and correction. A failing message is typically moved to a dedicated queue called a dead-letter 
  queue. To avoid overloading the infrastructure during temporary failure, for example, a network error, it 
  must be possible to configure how often retries are performed, preferably with an increasing length of 
  time between each retry.
- Guaranteed order and partitions If the business logic requires that messages are consumed and processed 
  in the same order as they were sent, we cannot use multiple instances per consumer to increase processing 
  performance; for example, we cannot use consumer groups. This might, in some cases, lead to an unacceptable 
  latency in the processing of incoming messages. We can use partitions to ensure that messages are delivered 
  in the same order as they were sent but without losing performance and scalability. In most cases, strict 
  order in the processing of messages is only required for messages that affect the same business entities. 
  For example, messages affecting the product with product ID 1 can, in many cases, be processed independently 
  of messages that affect the product with product ID 2. This means that the order only needs to be guaranteed 
  for messages that have the same product ID. The solution to this is to make it possible to specify a key for 
  each message, which the messaging system can use to guarantee that the order is kept between messages with 
  the same key. This can be solved by introducing sub-topics, also known as partitions, in a topic. The messaging 
  system places messages in a specific partition based on its key. Messages with the same key are always placed 
  in the same partition. The messaging system only needs to guarantee the delivery order for messages in the 
  same partition. To ensure the order of the messages, we configure one consumer instance per partition within 
  a consumer group. By increasing the number of partitions, we can allow a consumer to increase its number of 
  instances. This increases its message-processing performance without losing the delivery order.

-- When using Spring Cloud Stream with Kafka, events are retained in the topics, even after 
   consumers have processed them. However, when using Spring Cloud Stream with RabbitMQ, 
   the events are removed after they have been processed successfully.
   To be able to see what events have been published on each topic, Spring Cloud Stream is configured
   to save published events in a separate consumer group, auditGroup, per topic.

-- Spring Cloud Config supports storing configuration files in a number of different backends, such as: 
• A Git repository, for example, on GitHub or Bitbucket
• A local filesystem
• HashiCorp Vault
• A JDBC database

## fault tolerance mechanisms 
- A circuit breaker is used to prevent a chain of failure reaction if a remote service stops responding.
- A rate limiter is used to limit the number of requests to a service during a specified time period.
- A bulkhead is used to limit the number of concurrent requests to a service.
  Retries are used to handle random errors that might happen from time to time.
- A time limiter is used to avoid waiting too long for a response from a slow or unresponsive service.

-- The idea behind round-robin DNS is that each instance of a microservice registers its IP address under the same 
   name in a DNS server. When a client asks for IP addresses for the DNS name, the DNS server will return a list of 
   IP addresses for the registered instances. The client can use this list of IP addresses to send requests 
   to the microservice instances in a round-robin fashion, using the IP addresses one after another.

## Eureka configuration parameters
- Parameters for the Eureka server, prefixed with eureka.server.
- Parameters for Eureka clients, prefixed with eureka.client. This is for clients who want to
  communicate with a Eureka server.
- Parameters for Eureka instances, prefixed with eureka.instance. This is for the microservice
  instances that want to register themselves in the Eureka server.


# A route is defined by the following:
• Predicates, which select a route based on information in the incoming HTTP request
• Filters, which can modify both the request and/or the response
• A destination URI, which describes where to send a request
• An ID, that is, the name of the route


# OAuth 2.0 components  
- Resource owner: The end user.
- Client: The third-party client application, for example, a web app or a native mobile app, that
  wants to call some protected APIs in the name of the end user.
- Resource server: The server that exposes the APIs that we want to protect.
- Authorization server: The authorization server issues tokens to the client after the resource
  owner, that is, the end user, has been authenticated. The management of user information and the 
  authentication of users are typically delegated, behind the scenes, to an Identity Provider (IdP)

++ A client is registered in the authorization server and is given a client ID and a client secret. The client
   secret must be protected by the client, like a password. A client also gets registered with a set of 
   allowed redirect URIs that the authorization server will use after a user has been authenticated to send
   authorization codes and tokens that have been issued back to the client application.

# The OAuth 2.0 specification defines four authorization grant flows for issuing access tokens: 
- Authorization code grant flow: This is the safest, but also the most complex, grant flow. This grant flow 
  requires that the user interacts with the authorization server using a web browser for authentication 
  and giving consent to the client application, 
- Implicit grant flow: This flow is also web browser-based but intended for client applications that are 
  not able to keep a client secret protected, for example, a single-page web application. The web browser 
  gets an access token back from the authorization server instead of an authorization code. Since the implicit 
  grant flow is less secure than the authorization code grant flow, the client can’t request a refresh token.
- Resource owner password credentials grant flow: If a client application can’t interact with a web browser, 
  it can fall back on this grant flow. In this grant flow, the user must share their credentials with the 
  client application and the client application will use these credentials to acquire an access token.
- Client credentials grant flow: In the case where a client application needs to call an API unrelated to a 
  specific user, it can use this grant flow to acquire an access token using its own client ID and client secret.

# The most important improvements in OAuth 2.1 are:
- PKCE is integrated into the authorization code grant flow. The use of PKCE will be required by public 
  clients to improve their security, as described above. For confidential clients, where the authorization 
  server can verify their credentials, the use of PKCE is not required, only recommended.
- The implicit grant flow is deprecated and omitted from the specification, due to its less secure nature.
- The resource owner password credentials grant flow is also deprecated and omitted from the spec, for same reasons.

# When it comes to setting up a config server, there are a number of options to consider:
• Selecting a storage type for the configuration repository
• Deciding on the initial client connection, either to the config server or to the discovery server
• Securing the configuration, both against unauthorized access to the API and by avoiding storing
  sensitive information in plain text in the configuration repository


Introducing the retry mechanism
  The retry mechanism is very useful for random and infrequent faults, such as temporary network
  glitches. The retry mechanism can simply retry a failed request a number of times with a configurable
  delay between the attempts. One very important restriction on the use of the retry mechanism is that
  the services that it retries must be idempotent, that is, calling the service one or many times with the
  same request parameters gives the same result. For example, reading information is idempotent, but
  creating information is typically not. You don’t want a retry mechanism to accidentally create two
  orders just because the response from the first order’s creation got lost in the network.


# Micrometer Tracing
  By default, trace headers are propagated between microservices using W3C trace context headers 
  (https://www.w3.org/TR/trace-context/), most importantly the traceparent header, but can be
  configured to use OpenZipkin’s B3 headers

# A sample W3C trace context traceparent header looks like this:
  traceparent:"00-2425f26083814f66c985c717a761e810-fbec8704028cfb20-01"
++ The value of the traceparent header contains four parts, separated by a -:
• 00, indicates the version used. Will always be “00" using the current specification.
• 124...810, is the trace ID.
• fbe...b20 is the span ID.
• 01, the last part, contains various flags. The only flag supported by the current specification
  is a flag named sampled, with the value 01. It means that the caller is recording the trace data
  for this request. We will configure our microservices to record trace data for all requests, so
  this flag will always have the value of 01.

++ Use of OpenZipkin Brave B3 headers will look like this:
    X-B3-TraceId:"64436ea679e8eb6e6fa028bb3459e703"
    X-B3-SpanId:"120678270898ddd5"
    X-B3-ParentSpanId:"3c431d3d01987c22"
    X-B3-Sampled:"1"

++ Traces and spans are created automatically by Spring Boot for incoming traffic, both for incoming HTTP 
   requests and messages received by Spring Cloud Stream. If an incoming request contains a trace ID, it will 
   be used when creating spans; if not, a new trace id will be created. Trace and span IDs are automatically 
   propagated to outgoing traffic, either as HTTP requests or by sending messages using Spring Cloud Stream.

# Project Reactor, and Micrometer Tracing
  the current versions of Spring Boot, Project Reactor, and Micrometer Tracing do not yet work together 
  perfectly. Therefore, a couple of workarounds have been applied to the source code for reactive clients. 
  That is, the four microservices and the gateway. The problems are mainly related to the complexity of 
  propagating trace contexts (for example, trace and span IDs) between different threads involved in reactive 
  asynchronous processing, specifically if parts of the processing involve imperative synchronous processing.
++ If all processing of a request is done with a synchronous implementation, using one and the
   same thread for all processing, propagating trace context is not an issue. A ThreadLocal variable 
   can be used to store the trace context. The trace context can be retrieved from the ThreadLocal variable 
   in any place of the implementation since all code runs in one and the same thread.


# Helm templates and values
- The most frequently used parts of the built-in objects are:
• Values: Used to refer to values in the chart’s values.yaml file or values supplied when running
  a Helm command like install.
• Release: Used to provide metadata regarding the current release that is installed. It contains
  fields like:
• Name: The name of the release
• Namespace: The name of the namespace where the installation is performed
• Service: The name of the installation Service, always returning Helm

• Chart: Used to access information from the Chart.yaml file. Examples of fields that can be
  useful for providing metadata for a Deployment are:
  • Name: The name of the chart
  • Version: The chart’s version number
• Files: Containing functions for accessing chart-specific files. In this chapter we will use the
  following two functions in the Files object:
  • Glob: Returns files in a chart based on a glob pattern. For example, the pattern "config-repo/*" will 
    return all files found in the folder config-repo
  • AsConfig: Returns the content of files as a YAML map appropriate for declaring values in a ConfigMap
• Capabilities: Can be used to find information regarding the capabilities of the Kubernetes
  cluster that the installation is performed on. For example, a template can use information
  in this object to adopt a manifest based on what API versions the actual Kubernetes cluster
  supports. We will not use this object in this chapter, but I think it is in our interest to be aware
  of it for more advanced use cases.

-- Named templates, which will only be used by other templates and not used to create manifests themselves, 
   must have a name that starts with an underscore, _. This is used to prevent Helm from trying to create 
   manifests using them alone.


Introducing service meshes using Istio
- One of the core components in a service mesh is a lightweight proxy component, which is injected into each 
  microservice that will be part of the service mesh. All traffic in and out of a microservice is configured 
  to go through its proxy component. The proxy components are configured at runtime by a control plane in 
  the service mesh, using APIs exposed by the proxy. The control plane also collects telemetry data through 
  these APIs from the proxies to visualize how the traffic flows in the service mesh. 
  A service mesh also contains a data plane, consisting of the proxy components together with separate components 
  for handling external traffic to and from the service mesh, known as an ingress gateway and an egress gateway, 
  respectively. The gateway components also communicate with the control plane using a proxy component. 


- When deploying Istio on Kubernetes, most of its runtime components are deployed in a separate
  Kubernetes namespace, istio-system. For the configuration we will use in this book, we will find
  the following Deployments in this Namespace:
+ istiod, Istio’s daemon that runs the whole control plane.
+ istio-ingressgateway and istio-egressgateway, Istio’s ingress and egress gateway 
  components, are part of the data plane.
+ A number of integrations with other popular open source projects are supported by Istio to bring in 
  extra functionality to the control plane. In this book, we will integrate the following components:
  - Kiali: Provides observability to the service mesh, visualizing what is going on in the
    mesh. For more information, see https://www.kiali.io.
  - Tracing: Handles and visualizes distributed tracing information, based on either Jaeger
    or Zipkin. We will use Jaeger. For more information, see https://www.jaegertracing.io.
  - Prometheus: Performs data ingestion and storage for time-series-based data, for example, 
    performance metrics. For more information, see https://prometheus.io. 
  - Grafana: Visualizes performance metrics and other time-series-related data collected
    by Prometheus. For more information, see https://grafana.com.


Book, we will use the following Istio objects: 
- Gateway is used to configure how to handle incoming traffic to, and outgoing traffic from, the service mesh. 
  A gateway depends on a virtual service routing the incoming traffic to Kubernetes Services. We will use a 
  gateway object to accept incoming traffic to DNS names ending with minikube.me, using HTTPS. The Istio 
  gateway objects will replace the Ingress objects used in the previous chapter. Refer to the Replacing 
  Kubernetes Ingress Controller with Istio ingress gateway section for details.
- VirtualService is used to define routing rules in the service mesh. We will use virtual Services to describe 
  how to route incoming traffic from an Istio gateway to the Kubernetes Services and between Services. We 
  will also use virtual Services to inject faults and delays to test the reliability and resilience 
  capabilities of the service mesh.
- DestinationRule is used to define policies and rules for traffic that is routed (using a virtual service) 
  to a specific service (that is, a destination). We will use destination rules to set up encryption policies 
  to encrypt internal HTTP traffic and define service subsets that describe available versions of the services. 
  We will use service subsets when performing zero-downtime (blue-green) deployments from an existing 
  version of a microservice to a new version.
- PeerAuthentication is used to control service-to-service authentication inside the service
  mesh. Istio can protect communication between services in a service mesh by automatically
  provisioning mutual TLS (mTLS) for transport authentication, where client services are au-
  thenticated by using a client certificate that is provided by Istio. To allow Kubernetes to call
  liveness and readiness probes using plain HTTP, we will configure Istio to allow a mix of mTLS
  and plain HTTP, called PERMISSIVE mode.
- RequestAuthentication is used to authenticate end users based on the credentials provided in a request. 
  Istio supports using JSON Web Tokens (JWTs) in general and specifically when used according to the OpenID 
  Connect (OIDC) specification. Istio supports the use of the standard discovery endpoint in OIDC to specify 
  where Istio can fetch the public key set JSON Web Key Set (JWKS) to validate the signatures of the JWTs. We 
  will configure Istio to authenticate external requests using the auth server by specifying its JWKS 
  discovery endpoint. For a recap, see Chapter 11, Securing Access to APIs.
- AuthorizationPolicy is used to provide access control in Istio. We will not use Istio’s access control in 
  this book. Instead, we will reuse the existing access control implemented in the product-composite 
  microservice. We will therefore configure an AuthorizationPolicy object that allows access to the 
  product-composite microservice for any authenticated user, that is, for requests that contain a valid 
  JWT in the form of an OIDC access token.

-- An Istio ingress gateway has a number of advantages over a Kubernetes Ingress controller:
- It can report telemetry data to the control plane for the traffic that flows through it
- It can be used for more fine-grained routing
- It can both authenticate and authorize requests before routing them into the service mesh

Virtual services and destination rules
  To split the traffic between two versions of a microservice, we need to specify the weight distribution
  between the two versions in a virtual service, on the sender side. The virtual service will spread the
  traffic between two subsets, called old and new . The exact meaning of the new and old subset is defined
  in a corresponding DestinationRule, on the receiver side. It uses labels to determine which Pods
  run the old and new versions of the microservice.

