
Reactive microservices
  Traditionally, as Java developers, we are used to implementing synchronous communication using blocking 
  I/O, for example, a RESTful JSON API over HTTP. Using a blocking I/O means that a thread is allocated 
  from the operating system for the length of the request. If the number of concurrent requests goes up, a 
  server might run out of available threads in the operating system, causing problems ranging from longer 
  response times to crashing servers. Using a microservice architecture typically makes this problem even worse, 
  where typically a chain of cooperating microservices is used to serve a request. The more microservices involved 
  in serving a request, the faster the available threads will be drained.
Solution
  Use non-blocking I/O to ensure that no threads are allocated while waiting for processing 
  to occur in another service, that is, a database or another microservice.

A fat JAR file contains not only the classes and resource files of the application itself but also all the JAR 
  files the application depends on. This means that the fat JAR file is the only JAR file required to run the 
  application; that is, we only need to transfer one JAR file to an environment where we want to run the application 
  instead of transferring the application’s JAR file along with all the JAR files the application depends on.

Spring Data
Entity
  An entity describes the data that will be stored by Spring Data. Entity classes are, in general, annotated 
  with a mix of generic Spring Data annotations and annotations that are specific to each database technology.
  (like: @Table(name = "review") for sql dbs,  and @Document for nosql dbs)
  
Repositories
  Repositories are used to store and access data from different types of databases. In its most basic form, 
  a repository can be declared as a Java interface, and Spring Data will generate its implementation on the 
  fly using opinionated conventions. These conventions can be overridden and/or complemented by additional 
  configuration and, if required, some Java code.
  Spring Data also comes with some base Java interfaces, for example, CrudRepository, to make the definition 
  of a repository even simpler. The base interface, CrudRepository, provides us with standard methods for 
  create, read, update, and delete operations.

The core concepts in Spring Cloud Stream are as follows:
-- Message: A data structure that’s used to describe data sent to and received from a messaging system.
-- Publisher: Sends messages to the messaging system, also known as a Supplier.
-- Subscriber: Receives messages from the messaging system, also known as a Consumer.
-- Destination: Used to communicate with the messaging system. Publishers use output destinations and 
   subscribers use input destinations. Destinations are mapped by the specific binders to queues and topics 
   in the underlying messaging system.
-- Binder: A binder provides the actual integration with a specific messaging system, similar to
   what a JDBC driver does for a specific type of database.


plugins {
  id 'java'
  id 'org.springframework.boot' version '3.0.4'
  id 'io.spring.dependency-management' version '1.1.0'
}

-- The java plugin adds the Java compiler to the project.
-- The plugins org.springframework.boot and io.spring.dependency-management are declared,
   which together ensure that Gradle will build a fat JAR file and that we don’t need to specify any
   explicit version numbers on our Spring Boot starter dependencies. Instead, they are implied
   by the version of the org.springframework.boot plugin, that is, 3.0.4.

# in ./03-dockerize/ application.yml files:  Spring profiles can be used to specify the environment-specific 
  configuration, which, in this case, is a configuration that is only to be used when running the microservice 
  in a Docker container. Other examples are configurations that are specific to dev, test, and production 
  environments. Values in a profile override values from the default profile. By using YAML files, 
  multiple Spring profiles can be placed in the same file, separated by ---.

# When it comes to handling the suboptimal packaging of fat JAR files in Docker images, Spring Boot
  addressed this issue in v2.3.0, making it possible to extract the content of a fat JAR file into a number
  of folders. By default, Spring Boot creates the following folders after extracting a fat JAR file:
• dependencies, containing all dependencies as JAR files
• spring-boot-loader, containing Spring Boot classes that know how to start a Spring Boot application
• snapshot-dependencies, containing snapshot dependencies, if any
• application, containing application class files and resources

Writing automated tests that focus on persistence: 
  When writing persistence tests, we want to start a database when the tests begin and tear it down
  when the tests are complete. However, we don’t want the tests to wait for other resources to start up,
  for example, a web server such as Netty (which is required at runtime).
  Spring Boot comes with two class-level annotations tailored to this specific requirement:
- @DataMongoTest: This annotation starts up a MongoDB database when the test starts.
- @DataJpaTest: This annotation starts up a SQL database when the test starts:
   • By default, Spring Boot configures the tests to roll back updates to the SQL database to 
     minimize the risk of negative side effects on other tests. In our case, this behavior will cause 
     some of the tests to fail. Therefore, automatic rollback is disabled with the class-level 
     annotation @Transactional(propagation = NOT_SUPPORTED).

-- The reactive support in Spring 5 is based on Project Reactor (https://projectreactor.io). Project Reactor 
   is based on the Reactive Streams specification (http://www.reactive-streams.org), a standard for building
   reactive applications. Project Reactor is fundamental – it is what Spring WebFlux, Spring WebClient, and 
   Spring Data rely on to provide their reactive and non-blocking features.
   The programming model is based on processing streams of data, and the core data types in Project
   Reactor are Flux and Mono. A Flux object is used to process a stream of 0...n elements and a Mono
   object is used to process a stream that either is empty or returns at most one element
   
## Spring Cloud Stream
-- The programming model is based on a functional paradigm, where functions implementing one of
   the functional interfaces Supplier, Function, or Consumer in the java.util.function package can
   be chained together to perform decoupled event-based processing. To trigger such functional-based
   processing externally, from non-functional code, the helper class StreamBridge can be used

# Handling challenges with messaging
- Consumer groups
  The problem here is, if we scale up the number of instances of a message consumer, for example, if
  we start two instances of the product microservice, both instances of the product microservice will
  consume the same messages,
- Retries and dead-letter queues If a consumer fails to process a message, it may be re-queued for the 
  failing consumer until it is successfully processed. If the content of the message is invalid, also 
  known as a poisoned message, the message will block the consumer from processing other messages until 
  it is manually removed. If the failure is due to a temporary problem, for example, the database can’t be 
  reached due to a temporary network error, the processing will probably succeed after a number of retries.
  It must be possible to specify the number of retries until a message is moved to another storage for fault 
  analysis and correction. A failing message is typically moved to a dedicated queue called a dead-letter 
  queue. To avoid overloading the infrastructure during temporary failure, for example, a network error, it 
  must be possible to configure how often retries are performed, preferably with an increasing length of 
  time between each retry.
- Guaranteed order and partitions If the business logic requires that messages are consumed and processed 
  in the same order as they were sent, we cannot use multiple instances per consumer to increase processing 
  performance; for example, we cannot use consumer groups. This might, in some cases, lead to an unacceptable 
  latency in the processing of incoming messages. We can use partitions to ensure that messages are delivered 
  in the same order as they were sent but without losing performance and scalability. In most cases, strict 
  order in the processing of messages is only required for messages that affect the same business entities. 
  For example, messages affecting the product with product ID 1 can, in many cases, be processed independently 
  of messages that affect the product with product ID 2. This means that the order only needs to be guaranteed 
  for messages that have the same product ID. The solution to this is to make it possible to specify a key for 
  each message, which the messaging system can use to guarantee that the order is kept between messages with 
  the same key. This can be solved by introducing sub-topics, also known as partitions, in a topic. The messaging 
  system places messages in a specific partition based on its key. Messages with the same key are always placed 
  in the same partition. The messaging system only needs to guarantee the delivery order for messages in the 
  same partition. To ensure the order of the messages, we configure one consumer instance per partition within 
  a consumer group. By increasing the number of partitions, we can allow a consumer to increase its number of 
  instances. This increases its message-processing performance without losing the delivery order.

-- When using Spring Cloud Stream with Kafka, events are retained in the topics, even after 
   consumers have processed them. However, when using Spring Cloud Stream with RabbitMQ, 
   the events are removed after they have been processed successfully.
   To be able to see what events have been published on each topic, Spring Cloud Stream is configured
   to save published events in a separate consumer group, auditGroup, per topic.

-- Spring Cloud Config supports storing configuration files in a number of different backends, such as: 
• A Git repository, for example, on GitHub or Bitbucket
• A local filesystem
• HashiCorp Vault
• A JDBC database

## fault tolerance mechanisms 
- A circuit breaker is used to prevent a chain of failure reaction if a remote service stops responding.
- A rate limiter is used to limit the number of requests to a service during a specified time period.
- A bulkhead is used to limit the number of concurrent requests to a service.
  Retries are used to handle random errors that might happen from time to time.
- A time limiter is used to avoid waiting too long for a response from a slow or unresponsive service.

-- The idea behind round-robin DNS is that each instance of a microservice registers its IP address under the same 
   name in a DNS server. When a client asks for IP addresses for the DNS name, the DNS server will return a list of 
   IP addresses for the registered instances. The client can use this list of IP addresses to send requests 
   to the microservice instances in a round-robin fashion, using the IP addresses one after another.

## Eureka configuration parameters
- Parameters for the Eureka server, prefixed with eureka.server.
- Parameters for Eureka clients, prefixed with eureka.client. This is for clients who want to
  communicate with a Eureka server.
- Parameters for Eureka instances, prefixed with eureka.instance. This is for the microservice
  instances that want to register themselves in the Eureka server.


# A route is defined by the following:
• Predicates, which select a route based on information in the incoming HTTP request
• Filters, which can modify both the request and/or the response
• A destination URI, which describes where to send a request
• An ID, that is, the name of the route


# OAuth 2.0 components  
- Resource owner: The end user.
- Client: The third-party client application, for example, a web app or a native mobile app, that
  wants to call some protected APIs in the name of the end user.
- Resource server: The server that exposes the APIs that we want to protect.
- Authorization server: The authorization server issues tokens to the client after the resource
  owner, that is, the end user, has been authenticated. The management of user information and the 
  authentication of users are typically delegated, behind the scenes, to an Identity Provider (IdP)

++ A client is registered in the authorization server and is given a client ID and a client secret. The client
   secret must be protected by the client, like a password. A client also gets registered with a set of 
   allowed redirect URIs that the authorization server will use after a user has been authenticated to send
   authorization codes and tokens that have been issued back to the client application.

# The OAuth 2.0 specification defines four authorization grant flows for issuing access tokens: 
- Authorization code grant flow: This is the safest, but also the most complex, grant flow. This grant flow 
  requires that the user interacts with the authorization server using a web browser for authentication 
  and giving consent to the client application, 
- Implicit grant flow: This flow is also web browser-based but intended for client applications that are 
  not able to keep a client secret protected, for example, a single-page web application. The web browser 
  gets an access token back from the authorization server instead of an authorization code. Since the implicit 
  grant flow is less secure than the authorization code grant flow, the client can’t request a refresh token.
- Resource owner password credentials grant flow: If a client application can’t interact with a web browser, 
  it can fall back on this grant flow. In this grant flow, the user must share their credentials with the 
  client application and the client application will use these credentials to acquire an access token.
- Client credentials grant flow: In the case where a client application needs to call an API unrelated to a 
  specific user, it can use this grant flow to acquire an access token using its own client ID and client secret.

# The most important improvements in OAuth 2.1 are:
- PKCE is integrated into the authorization code grant flow. The use of PKCE will be required by public 
  clients to improve their security, as described above. For confidential clients, where the authorization 
  server can verify their credentials, the use of PKCE is not required, only recommended.
- The implicit grant flow is deprecated and omitted from the specification, due to its less secure nature.
- The resource owner password credentials grant flow is also deprecated and omitted from the spec, for same reasons.

# When it comes to setting up a config server, there are a number of options to consider:
• Selecting a storage type for the configuration repository
• Deciding on the initial client connection, either to the config server or to the discovery server
• Securing the configuration, both against unauthorized access to the API and by avoiding storing
  sensitive information in plain text in the configuration repository

