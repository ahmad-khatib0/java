version: '2.1'

# RUN
# export COMPOSE_FILE=docker-compose-kafka.yml
# docker-compose build && docker-compose up -d
#
# create two products, one with the product ID set to 1 and one with the product ID set to 2.
#
# see the list of topics
# docker-compose exec kafka kafka-topics --bootstrap-server localhost:9092 --list
# Here is what we see in the preceding output:
# • The topics prefixed with error are the topics corresponding to dead-letter queues.
# • You will not find any auditGroup groups as in the case of RabbitMQ. Since events are retained
#   in the topics by Kafka, even after consumers have processed them,
#
# To see the partitions in a specific topic, for example, the products topic,
# docker-compose exec kafka kafka-topics --bootstrap-server localhost:9092 --describe --topic products
#
# To see all the messages in a specific partition, for example, partition 1 in the products topic,
# docker-compose exec kafka kafka-console-consumer --bootstrap-server \
# localhost:9092 --topic products --from-beginning --timeout-ms 1000 --partition 1
#
# CLEAN
# docker-compose down
# unset COMPOSE_FILE
services:
  product:
    build: microservices/product-service
    mem_limit: 512m
    environment:
      - SPRING_PROFILES_ACTIVE=docker,streaming_partitioned,streaming_instance_0,kafka
    depends_on:
      mongodb:
        condition: service_healthy
      kafka:
        condition: service_started

  product-p1:
    build: microservices/product-service
    mem_limit: 512m
    environment:
      - SPRING_PROFILES_ACTIVE=docker,streaming_partitioned,streaming_instance_1,kafka
    depends_on:
      mongodb:
        condition: service_healthy
      kafka:
        condition: service_started

  recommendation:
    build: microservices/recommendation-service
    mem_limit: 512m
    environment:
      - SPRING_PROFILES_ACTIVE=docker,streaming_partitioned,streaming_instance_0,kafka
    depends_on:
      mongodb:
        condition: service_healthy
      kafka:
        condition: service_started

  recommendation-p1:
    build: microservices/recommendation-service
    mem_limit: 512m
    environment:
      - SPRING_PROFILES_ACTIVE=docker,streaming_partitioned,streaming_instance_1,kafka
    depends_on:
      mongodb:
        condition: service_healthy
      kafka:
        condition: service_started

  review:
    build: microservices/review-service
    mem_limit: 512m
    environment:
      - SPRING_PROFILES_ACTIVE=docker,streaming_partitioned,streaming_instance_0,kafka
    depends_on:
      mysql:
        condition: service_healthy
      kafka:
        condition: service_started

  review-p1:
    build: microservices/review-service
    mem_limit: 512m
    environment:
      - SPRING_PROFILES_ACTIVE=docker,streaming_partitioned,streaming_instance_1,kafka
    depends_on:
      mysql:
        condition: service_healthy
      kafka:
        condition: service_started

  product-composite:
    build: microservices/product-composite-service
    mem_limit: 512m
    ports:
      - '8080:8080'
    environment:
      - SPRING_PROFILES_ACTIVE=docker,streaming_partitioned,kafka
    depends_on:
      kafka:
        condition: service_started

  mongodb:
    image: mongo:6.0.4
    mem_limit: 512m
    ports:
      - '27017:27017'
    command: mongod
    healthcheck:
      test: 'mongostat -n 1'
      interval: 5s
      timeout: 2s
      retries: 60

  mysql:
    image: mysql:8.0.32
    mem_limit: 512m
    ports:
      - '3306:3306'
    environment:
      - MYSQL_ROOT_PASSWORD=rootpwd
      - MYSQL_DATABASE=review-db
      - MYSQL_USER=user
      - MYSQL_PASSWORD=pwd
    healthcheck:
      test: '/usr/bin/mysql --user=user --password=pwd --execute "SHOW DATABASES;"'
      interval: 5s
      timeout: 2s
      retries: 60

  kafka:
    image: confluentinc/cp-kafka:7.3.1
    restart: always
    mem_limit: 1024m
    ports:
      - '9092:9092'
    environment:
      - KAFKA_ZOOKEEPER_CONNECT=zookeeper:2181
      - KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://kafka:9092
      - KAFKA_BROKER_ID=1
      - KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR=1
    depends_on:
      - zookeeper

  zookeeper:
    image: confluentinc/cp-zookeeper:7.3.1
    restart: always
    mem_limit: 512m
    ports:
      - '2181:2181'
    environment:
      - ZOOKEEPER_CLIENT_PORT=2181
