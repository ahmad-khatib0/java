# • Source elements that tail container log files and log files from processes that run outside of
#   Kubernetes, for example, kubelet and the Docker daemon. The source elements also tag the
#   log records from Kubernetes with the full name of the log file with / replaced by . and prefixed
#   with kubernetes. Since the tag is based on the full filename, the name contains the name of
#   the namespace, pod, and container, among other things. So, the tag is very useful for finding
#   log records of interest by matching the tag.
#   For example, the tag from the product-composite microservice could be something like
#   kubernetes.var.log.containers.product-composite-7...s_hands-on_comp-e...b.log,
#   while the tag for the corresponding istio-proxy in the same Pod could be something like
#   kubernetes.var.log.containers.product-composite-7...s_hands-on_istio-proxy-1...3.log.
# • A filter element that enriches the log records that come from containers running inside Ku-
#   bernetes, along with Kubernetes-specific fields that contain information such as the names
# of the containers and the namespace they run in.

apiVersion: v1
kind: ConfigMap
metadata:
  name: fluentd-hands-on-config
  namespace: kube-system
data:
  # the rewrite_tag_filter plugin.
  # This plugin can be used for routing log records based on the concept of changing
  # the name of a tag and then re-emitting the log record to the Fluentd routing engine.
  #
  # - The tags of all log records from Istio, including istio-proxy, are prefixed with istio so that
  # they can be separated from the Spring Boot-based log records.
  # - The tags of all log records from the hands-on namespace (except for the log records from
  # istio-proxy) are prefixed with spring-boot.
  # - The log records from Spring Boot are checked for the presence of multiline stack traces. If the
  # log record is part of a multiline stack trace, it is processed by the third-party detect-exceptions
  # plugin to recreate the stack trace. Otherwise, it is parsed using a regular expression to extract
  # information of interest. See the Deploying Fluentd section for details on this third-party plugin.
  #
  #
  # - The <match> element matches any tags that follow the kubernetes.**istio** pattern,
  # that is, tags that start with Kubernetes and then contain the word istio somewhere in
  # the tag name. istio can come from the name of either the namespace or the container;
  # both are part of the tag.
  # - The <match> element contains only one <rule> element, which prefixes the tag with
  # istio. The ${tag} variable holds the current value of the tag.
  # - Since this is the only <rule> element in the <match> element, it is configured to match
  # all log records.
  # - Since all log records that come from Kubernetes have a log field, the key field is set to
  # log, that is, the rule looks for a log field in the log records.
  # - To match any string in the log field, the pattern field is set to the ^(.*)$ regular ex-
  # pression. ^ marks the beginning of a string, while $ marks the end of a string. (.*)
  # matches any number of characters, except for line breaks.
  # - The log records are re-emitted to the Fluentd routing engine. Since no other elements
  # in the configuration file match tags starting with istio, the log records will be sent
  # directly to the output element for Elasticsearch, which is defined in the fluent.conf
  # file we described previously.

  fluentd-hands-on.conf: |

    <match kubernetes.**istio**>
      @type rewrite_tag_filter
      <rule>
        key log
        pattern ^(.*)$
        tag istio.${tag}
      </rule>
    </match>

    # matches all log records from the hands-on namespace, that is,
    # the log records that are emitted by our microservices. 
    <match kubernetes.**hands-on**>
      @type rewrite_tag_filter
      <rule>
        key log
        pattern ^(.*)$
        tag spring-boot.${tag}
      </rule>
    </match>

    # matches spring-boot log records and determines whether they
    # are ordinary Spring Boot log records or part of a multiline stack trace. Since Spring Boot 3,
    # Project Reactor has added extra information to stack traces to clarify what caused an exception.
    <match spring-boot.**>
      @type rewrite_tag_filter
      <rule>
        key log
        pattern /^\d{4}-\d{2}-\d{2}T\d{2}:\d{2}:\d{2}\.\d{3}([-+]\d{2}:\d{2}|Z).*/
        tag parse.${tag}
      </rule>
      # Get rid of Reactor debug info:
      #
      #   Suppressed: reactor.core.publisher.FluxOnAssembly$OnAssemblyException:
      # Error has been observed at the following site(s):
      #   *__checkpoint ⇢ Handler se.magnus.microservices.core.product.services.ProductServiceImpl#getProduct(HttpHeaders, int, int, int) [DispatcherHandler]
      #   *__checkpoint ⇢ org.springframework.web.filter.reactive.ServerHttpObservationFilter [DefaultWebFilterChain]
      #   *__checkpoint ⇢ HTTP GET "/product/1?faultPercent=100" [ExceptionHandlingWebHandler]
      # Original Stack Trace:
      <rule>
        key log
        pattern /^\s+Suppressed:.*$/
        tag skip.${tag}
      </rule>
      <rule>
        key log
        pattern /^Error has been observed at the following site.*/
        tag skip.${tag}
      </rule>
      <rule>
        key log
        pattern /^\s+\*__checkpoint.*/
        tag skip.${tag}
      </rule>
      <rule>
        key log
        pattern /^Original Stack Trace:.*/
        tag skip.${tag}
      </rule>

      <rule>
        key log
        pattern /^.*/
        tag check.exception.${tag}
      </rule>
    </match>

    <match skip.spring-boot.**>
      @type null
    </match>

    <match check.exception.spring-boot.**>
      @type detect_exceptions
      languages java
      remove_tag_prefix check
      message log
      multiline_flush_interval 5
    </match>

    <filter parse.spring-boot.**>
      @type parser
      key_name log
      time_key time
      time_format %Y-%m-%dT%H:%M:%S.%N
      reserve_data true
      # Sample log messages:
      # 2021-03-27T13:07:28.642Z DEBUG [product-composite,395ab9670bc9685096dddd66836d02e1,f32eb266bd1ff9a3] 1 --- [or-http-epoll-1] s.m.u.h.GlobalControllerExceptionHandler : Returning HTTP status: 404 NOT_FOUND for path: /product-composite/13, message: Product Id: 13 not found
      # 2021-03-27T13:07:28.642+01:00 DEBUG [product-composite,395ab9670bc9685096dddd66836d02e1,f32eb266bd1ff9a3] 1 --- [or-http-epoll-1] s.m.u.h.GlobalControllerExceptionHandler : Returning HTTP status: 404 NOT_FOUND for path: /product-composite/13, message: Product Id: 13 not found
      format /^(?<time>\d{4}-\d{2}-\d{2}T\d{2}:\d{2}:\d{2}\.\d{3}([-+]\d{2}:\d{2}|Z))\s+(?<spring.level>[^\s]+)\s+(\[(?<spring.service>[^,]*),(?<spring.trace>[^,]*),(?<spring.span>[^\]]*)]*\])\s+(?<spring.pid>\d+)\s+---\s+\[\s*(?<spring.thread>[^\]]+)\]\s+(?<spring.class>[^\s]+)\s*:\s+(?<log>.*)$/
    </filter>

# - The first uses a regular expression to check whether the log field in the log element
# starts with a timestamp or not.
# - If the log field starts with a timestamp, the log record is treated as an ordinary Spring
# Boot log record and its tag is prefixed with parse.
# - Next follows four rule elements that are used to filter out the extra information added
# by Project Reactor; they all prefix the tag with skip.
# - Otherwise, the last <rule> element will match, and the log record is handled as a
# multiline log record. Its tag is prefixed with check.exception.
# - The log record is re-emitted in either case and its tag will either start with check.
# exception.spring-boot, skip.spring-boot, or parse.spring-boot after this processing.
# - The fourth <match> element is used to get rid of the log output from Project Reactor, i.e. match
# tags starting with skip.spring-boot . The <match> element applies the null output plugin that
# throws away the events.
#
# - In the fifth <match> element, the selected log records have a tag that starts with check.exception.
#   spring-boot, that is, log records that are part of a multiline stack trace.
# The detect_exceptions plugin works like this:
# • The detect_exceptions plugin is used to combine multiple one-line log records into
#    a single log record that contains a complete stack trace.
# Before a multiline log record is re-emitted into the routing engine, the check prefix
# is removed from the tag to prevent a never-ending processing loop of the log record.
#
# Finally, the configuration file consists of a <filter> element that parses Spring Boot
# log messages using a regular expression, extracting information of interest.
# Note that filter elements don’t re-emit log records; instead, they just pass them on to the next
# element in the configuration file that matches the log record’s tag.
#
# The following fields are extracted from the Spring Boot log message
# that’s stored in the log field in the log record:
# <time>: The timestamp for when the log record was created
# <spring.level>: The log level of the log record: FATAL, ERROR, WARN, INFO, DEBUG, or TRACE
# <spring.service>: The name of the microservice
# <spring.trace>: The trace ID used to perform distributed tracing
# <spring.span>: The span ID, the ID of the part of the distributed processing that this
# microservice executed
# <spring.pid>: The process ID
# <spring.thread> : The thread ID
# <spring.class>: The name of the Java class
# <log>: The actual log message
#
# The names of Spring Boot-based microservices are specified using the spring.
# application.name property. This property has been added to each microservice-specif-
# ic property file in the config repository, in the config-repo folder.
