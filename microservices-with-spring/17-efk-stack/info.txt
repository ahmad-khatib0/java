
## Deploying the EFK stack on Kubernetes
$ eval $(minikube docker-env -u)
$ ./gradlew build
$ eval $(minikube docker-env)
$ docker-compose build

$ kubectl delete namespace hands-on
$ kubectl apply -f kubernetes/hands-on-namespace.yml
$ kubectl config set-context $(kubectl config current-context) --namespace=hands-on
$ for f in kubernetes/helm/components/*; do helm dep up $f; done
$ for f in kubernetes/helm/environments/*; do helm dep up $f; done
$ helm install hands-on-dev-env kubernetes/helm/environments/dev-env -n hands-on --wait
$ minikube tunnel
$ ./test-em-all.bash

# You can also try out the APIs manually by running the following commands:
$ ACCESS_TOKEN=$(curl -k https://writer:secret-writer@minikube.me/oauth2/token 
  -d grant_type=client_credentials -d scope="product:read product:write" -s | jq .access_token -r)
$ echo ACCESS_TOKEN=$ACCESS_TOKEN
$ curl -ks https://minikube.me/product-composite/1 -H "Authorization: Bearer $ACCESS_TOKEN" | jq .productId

## Deploy Elasticsearch and Kibana
# To make the deployment steps run faster, prefetch the Docker images
$ eval $(minikube docker-env)
$ docker pull docker.elastic.co/elasticsearch/elasticsearch:7.17.10
$ docker pull docker.elastic.co/kibana/kibana:7.17.10
# Use the Helm chart to create the logging namespace, deploy Elasticsearch and Kibana in it and wait
$ helm install logging-hands-on-add-on kubernetes/helm/environments/logging -n logging --create-namespace --wait

# Verify that Elasticsearch is up and running with the following command:
$ curl https://elasticsearch.minikube.me -sk | jq -r .tagline
# Verify that Kibana is up and running with
$ curl https://kibana.minikube.me -kLs -o /dev/null -w "%{http_code}\n"

## Deploying Fluentd
$ eval $(minikube docker-env)
$ docker build -f kubernetes/efk/Dockerfile -t hands-on/fluentd:v1 kubernetes/efk/
# Create the ConfigMap, deploy Fluentd’s DaemonSet, and wait for the Pod to be ready
$ kubectl apply -f kubernetes/efk/fluentd-hands-on-configmap.yml
$ kubectl apply -f kubernetes/efk/fluentd-ds.yml
$ kubectl wait --timeout=120s --for=condition=Ready pod -l app=fluentd -n kube-system 
# Verify that the Fluentd Pod is healthy with:  
$ kubectl logs -n kube-system -l app=fluentd --tail=-1 | grep "fluentd worker is now running worker"

# After a minute or so, you can ask Elasticsearch how many log records have been collected 
$ curl https://elasticsearch.minikube.me/_all/_count -sk | jq .count


## Initializing Kibana
# Perform the following steps to initialize Kibana:
- Open Kibana’s web UI using the https://kibana.minikube.me URL in a web browser.
- On the Welcome home page, click on the hamburger menu ≡ (three horizontal lines) in the
  upper-left corner, and click on Stack Management at the bottom of the menu to the left.
- In the Management menu, go to the bottom and select Index Patterns.
- Click on the button named Create index pattern.
- Enter logstash-* as the index pattern name and click on the Next Step button.
- Click on the drop-down list for the Timestamp field and select the only available field, @timestamp.
- Click on the Create index pattern button.


## Perform the following steps to use the API to create log records and, after that, 
   use Kibana to look up the log records
$ ACCESS_TOKEN=$(curl -k https://writer:secret-writer@minikube.me/oauth2/token 
  -d grant_type=client_credentials -d scope="product:read product:write" -s | jq .access_token -r)
$ echo ACCESS_TOKEN=$ACCESS_TOKEN
$ curl -X POST -k https://minikube.me/product-composite -H "Content-Type: application/json" \
  -H "Authorization: Bearer $ACCESS_TOKEN" --data '{"productId":1234,"name":"product name 1234","weight":1234}'
$ curl -H "Authorization: Bearer $ACCESS_TOKEN" -k 'https://minikube.me/product-composite/1234' -s | jq .
 




